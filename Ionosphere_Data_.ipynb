{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dwtmiD9AWskc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import models,layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a4r5pVS0XNgt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02337</td>\n",
       "      <td>-0.00592</td>\n",
       "      <td>-0.09924</td>\n",
       "      <td>-0.11949</td>\n",
       "      <td>-0.00763</td>\n",
       "      <td>-0.11824</td>\n",
       "      <td>0.14706</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01535</td>\n",
       "      <td>-0.03240</td>\n",
       "      <td>0.09223</td>\n",
       "      <td>-0.07859</td>\n",
       "      <td>0.00732</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00039</td>\n",
       "      <td>0.12011</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97588</td>\n",
       "      <td>-0.10602</td>\n",
       "      <td>0.94601</td>\n",
       "      <td>-0.20800</td>\n",
       "      <td>0.92806</td>\n",
       "      <td>-0.28350</td>\n",
       "      <td>0.85996</td>\n",
       "      <td>-0.27342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.81634</td>\n",
       "      <td>0.13659</td>\n",
       "      <td>-0.82510</td>\n",
       "      <td>0.04606</td>\n",
       "      <td>-0.82395</td>\n",
       "      <td>-0.04262</td>\n",
       "      <td>-0.81318</td>\n",
       "      <td>-0.13832</td>\n",
       "      <td>-0.80975</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96355</td>\n",
       "      <td>-0.07198</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14333</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.21313</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.36174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65440</td>\n",
       "      <td>0.57577</td>\n",
       "      <td>-0.69712</td>\n",
       "      <td>0.25435</td>\n",
       "      <td>-0.63919</td>\n",
       "      <td>0.45114</td>\n",
       "      <td>-0.72779</td>\n",
       "      <td>0.38895</td>\n",
       "      <td>-0.73420</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01864</td>\n",
       "      <td>-0.08459</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>-0.26810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01326</td>\n",
       "      <td>0.20645</td>\n",
       "      <td>-0.02294</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.16595</td>\n",
       "      <td>0.24086</td>\n",
       "      <td>-0.08208</td>\n",
       "      <td>0.38065</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.06655</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18388</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.27320</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.43107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.89128</td>\n",
       "      <td>0.47211</td>\n",
       "      <td>-0.86500</td>\n",
       "      <td>0.40303</td>\n",
       "      <td>-0.83675</td>\n",
       "      <td>0.30996</td>\n",
       "      <td>-0.89093</td>\n",
       "      <td>0.22995</td>\n",
       "      <td>-0.89158</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.54210</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.36217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40888</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.62745</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.16316</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.10169</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>-0.15197</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.19277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47137</td>\n",
       "      <td>0.76224</td>\n",
       "      <td>-0.58370</td>\n",
       "      <td>0.65723</td>\n",
       "      <td>-0.68794</td>\n",
       "      <td>0.68714</td>\n",
       "      <td>-0.64537</td>\n",
       "      <td>0.64727</td>\n",
       "      <td>-0.67226</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.86701</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.22280</td>\n",
       "      <td>0.85492</td>\n",
       "      <td>-0.39896</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17012</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.35924</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.66494</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.88428</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18826</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.07380</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03420</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.05563</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.08764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20033</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.36743</td>\n",
       "      <td>0.95603</td>\n",
       "      <td>0.48641</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.32492</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.46712</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50932</td>\n",
       "      <td>-0.93996</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.26708</td>\n",
       "      <td>-0.03520</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92236</td>\n",
       "      <td>0.39752</td>\n",
       "      <td>0.26501</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.23188</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99645</td>\n",
       "      <td>0.06468</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.01236</td>\n",
       "      <td>0.97811</td>\n",
       "      <td>0.02498</td>\n",
       "      <td>0.96112</td>\n",
       "      <td>0.02312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13412</td>\n",
       "      <td>0.79476</td>\n",
       "      <td>0.13638</td>\n",
       "      <td>0.79110</td>\n",
       "      <td>0.15379</td>\n",
       "      <td>0.77122</td>\n",
       "      <td>0.15930</td>\n",
       "      <td>0.70941</td>\n",
       "      <td>0.12015</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67065</td>\n",
       "      <td>0.02528</td>\n",
       "      <td>0.66626</td>\n",
       "      <td>0.05031</td>\n",
       "      <td>0.57197</td>\n",
       "      <td>0.18761</td>\n",
       "      <td>0.08776</td>\n",
       "      <td>0.34081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23724</td>\n",
       "      <td>0.46167</td>\n",
       "      <td>0.24618</td>\n",
       "      <td>0.43433</td>\n",
       "      <td>0.25306</td>\n",
       "      <td>0.40663</td>\n",
       "      <td>0.25792</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.33036</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0          1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1          1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2          1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3          1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4          1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "5          1         0   0.02337  -0.00592  -0.09924  -0.11949  -0.00763   \n",
       "6          1         0   0.97588  -0.10602   0.94601  -0.20800   0.92806   \n",
       "7          0         0   0.00000   0.00000   0.00000   0.00000   1.00000   \n",
       "8          1         0   0.96355  -0.07198   1.00000  -0.14333   1.00000   \n",
       "9          1         0  -0.01864  -0.08459   0.00000   0.00000   0.00000   \n",
       "10         1         0   1.00000   0.06655   1.00000  -0.18388   1.00000   \n",
       "11         1         0   1.00000  -0.54210   1.00000  -1.00000   1.00000   \n",
       "12         1         0   1.00000  -0.16316   1.00000  -0.10169   0.99999   \n",
       "13         1         0   1.00000  -0.86701   1.00000   0.22280   0.85492   \n",
       "14         1         0   1.00000   0.07380   1.00000   0.03420   1.00000   \n",
       "15         1         0   0.50932  -0.93996   1.00000   0.26708  -0.03520   \n",
       "16         1         0   0.99645   0.06468   1.00000  -0.01236   0.97811   \n",
       "17         0         0   0.00000   0.00000  -1.00000  -1.00000   1.00000   \n",
       "18         1         0   0.67065   0.02528   0.66626   0.05031   0.57197   \n",
       "19         0         0   1.00000  -1.00000   0.00000   0.00000   0.00000   \n",
       "\n",
       "    feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0   -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1   -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2   -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3   -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4   -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "5   -0.11824   0.14706    0.06637  ...   -0.01535   -0.03240    0.09223   \n",
       "6   -0.28350   0.85996   -0.27342  ...   -0.81634    0.13659   -0.82510   \n",
       "7   -1.00000   0.00000    0.00000  ...    1.00000    1.00000    1.00000   \n",
       "8   -0.21313   1.00000   -0.36174  ...   -0.65440    0.57577   -0.69712   \n",
       "9    0.00000   0.11470   -0.26810  ...   -0.01326    0.20645   -0.02294   \n",
       "10  -0.27320   1.00000   -0.43107  ...   -0.89128    0.47211   -0.86500   \n",
       "11  -1.00000   1.00000    0.36217  ...   -0.40888    1.00000   -0.62745   \n",
       "12  -0.15197   1.00000   -0.19277  ...   -0.47137    0.76224   -0.58370   \n",
       "13  -0.39896   1.00000   -0.12090  ...   -0.17012    1.00000    0.35924   \n",
       "14  -0.05563   1.00000    0.08764  ...    0.20033    1.00000    0.36743   \n",
       "15  -1.00000   1.00000   -1.00000  ...    0.92236    0.39752    0.26501   \n",
       "16   0.02498   0.96112    0.02312  ...    0.13412    0.79476    0.13638   \n",
       "17   1.00000  -1.00000    1.00000  ...    1.00000    1.00000   -1.00000   \n",
       "18   0.18761   0.08776    0.34081  ...    0.23724    0.46167    0.24618   \n",
       "19   0.00000   1.00000    1.00000  ...    1.00000    1.00000    1.00000   \n",
       "\n",
       "    feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0     0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1    -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2     0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3     1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4     0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "5    -0.07859    0.00732    0.00000    0.00000   -0.00039    0.12011      b  \n",
       "6     0.04606   -0.82395   -0.04262   -0.81318   -0.13832   -0.80975      g  \n",
       "7     0.00000    0.00000    1.00000    1.00000    0.00000    0.00000      b  \n",
       "8     0.25435   -0.63919    0.45114   -0.72779    0.38895   -0.73420      g  \n",
       "9     0.00000    0.00000    0.16595    0.24086   -0.08208    0.38065      b  \n",
       "10    0.40303   -0.83675    0.30996   -0.89093    0.22995   -0.89158      g  \n",
       "11    1.00000   -1.00000    1.00000   -1.00000    1.00000   -1.00000      b  \n",
       "12    0.65723   -0.68794    0.68714   -0.64537    0.64727   -0.67226      g  \n",
       "13    1.00000   -0.66494    1.00000    0.88428    1.00000   -0.18826      b  \n",
       "14    0.95603    0.48641    1.00000    0.32492    1.00000    0.46712      g  \n",
       "15    0.00000    0.00000    1.00000    0.23188    0.00000    0.00000      b  \n",
       "16    0.79110    0.15379    0.77122    0.15930    0.70941    0.12015      g  \n",
       "17   -1.00000    1.00000   -1.00000   -1.00000    1.00000   -1.00000      b  \n",
       "18    0.43433    0.25306    0.40663    0.25792    1.00000    0.33036      g  \n",
       "19    1.00000   -1.00000    1.00000    1.00000    1.00000    1.00000      b  \n",
       "\n",
       "[20 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/asama/DL/Completed_Assignments/ionosphere_data.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "KEmVBlyYYgfz",
    "outputId": "72e08361-24f4-4f07-af69-670b1fd991af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "346         1         0   0.83508   0.08298   0.73739  -0.14706   0.84349   \n",
       "347         1         0   0.95113   0.00419   0.95183  -0.02723   0.93438   \n",
       "348         1         0   0.94701  -0.00034   0.93207  -0.03227   0.95177   \n",
       "349         1         0   0.90608  -0.01657   0.98122  -0.01989   0.95691   \n",
       "350         1         0   0.84710   0.13533   0.73638  -0.06151   0.87873   \n",
       "\n",
       "     feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "346  -0.05567   0.90441   -0.04622  ...   -0.04202    0.83479    0.00123   \n",
       "347  -0.01920   0.94590    0.01606  ...    0.01361    0.93522    0.04925   \n",
       "348  -0.03431   0.95584    0.02446  ...    0.03193    0.92489    0.02542   \n",
       "349  -0.03646   0.85746    0.00110  ...   -0.02099    0.89147   -0.07760   \n",
       "350   0.08260   0.88928   -0.09139  ...   -0.15114    0.81147   -0.04822   \n",
       "\n",
       "     feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "346    1.00000    0.12815    0.86660   -0.10714    0.90546   -0.04307      g  \n",
       "347    0.93159    0.08168    0.94066   -0.00035    0.91483    0.04712      g  \n",
       "348    0.92120    0.02242    0.92459    0.00442    0.92697   -0.00577      g  \n",
       "349    0.82983   -0.17238    0.96022   -0.03757    0.87403   -0.16243      g  \n",
       "350    0.78207   -0.00703    0.75747   -0.06678    0.85764   -0.06151      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myeiUWZjXfvS",
    "outputId": "d8203b46-4081-43c8-c27a-d3d25ca5dead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 35 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature1   351 non-null    int64  \n",
      " 1   feature2   351 non-null    int64  \n",
      " 2   feature3   351 non-null    float64\n",
      " 3   feature4   351 non-null    float64\n",
      " 4   feature5   351 non-null    float64\n",
      " 5   feature6   351 non-null    float64\n",
      " 6   feature7   351 non-null    float64\n",
      " 7   feature8   351 non-null    float64\n",
      " 8   feature9   351 non-null    float64\n",
      " 9   feature10  351 non-null    float64\n",
      " 10  feature11  351 non-null    float64\n",
      " 11  feature12  351 non-null    float64\n",
      " 12  feature13  351 non-null    float64\n",
      " 13  feature14  351 non-null    float64\n",
      " 14  feature15  351 non-null    float64\n",
      " 15  feature16  351 non-null    float64\n",
      " 16  feature17  351 non-null    float64\n",
      " 17  feature18  351 non-null    float64\n",
      " 18  feature19  351 non-null    float64\n",
      " 19  feature20  351 non-null    float64\n",
      " 20  feature21  351 non-null    float64\n",
      " 21  feature22  351 non-null    float64\n",
      " 22  feature23  351 non-null    float64\n",
      " 23  feature24  351 non-null    float64\n",
      " 24  feature25  351 non-null    float64\n",
      " 25  feature26  351 non-null    float64\n",
      " 26  feature27  351 non-null    float64\n",
      " 27  feature28  351 non-null    float64\n",
      " 28  feature29  351 non-null    float64\n",
      " 29  feature30  351 non-null    float64\n",
      " 30  feature31  351 non-null    float64\n",
      " 31  feature32  351 non-null    float64\n",
      " 32  feature33  351 non-null    float64\n",
      " 33  feature34  351 non-null    float64\n",
      " 34  label      351 non-null    object \n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 96.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ue-cW3oTYllM"
   },
   "outputs": [],
   "source": [
    "df[['feature1','feature2']]=df[['feature1','feature2']].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AimwE6BCZdBz",
    "outputId": "2cc5c5c5-4dd2-4c19-dd3c-39e6346fa5cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['label']=='g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wjgFQEH7ivRD"
   },
   "outputs": [],
   "source": [
    "df[df['label']=='g']=0\n",
    "df[df['label']=='b']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "w15kBSY9i4jR"
   },
   "outputs": [],
   "source": [
    "df['label']=df['label'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XK-KnyqlcOI1"
   },
   "outputs": [],
   "source": [
    "trg_val=int((60/100)*len(df))\n",
    "test_val=int((40/100)*len(df))\n",
    "\n",
    "test_data=df.loc[:test_val, :'feature34']\n",
    "test_label=df.loc[:test_val,'label']\n",
    "\n",
    "train_data=df.loc[trg_val: ,:'feature34']\n",
    "train_label=df.loc[trg_val: , 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8llbRTsnj7oA",
    "outputId": "b259f851-30a1-4e16-872e-b0d849c2879a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210    1.0\n",
       "211    0.0\n",
       "212    1.0\n",
       "213    0.0\n",
       "214    1.0\n",
       "      ... \n",
       "346    0.0\n",
       "347    0.0\n",
       "348    0.0\n",
       "349    0.0\n",
       "350    0.0\n",
       "Name: label, Length: 141, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "x0KxSINJdRtS"
   },
   "outputs": [],
   "source": [
    "mean=train_data.mean(axis=0)\n",
    "std=train_data.std(axis=0)\n",
    "\n",
    "train_data-=mean\n",
    "train_data/=std\n",
    "\n",
    "test_data-=mean\n",
    "test_data/=std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "23n0QpCedFDi"
   },
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Dense(24,activation='relu' ,input_shape=(34,)))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dense(8,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "a5E5od_FgYeP"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2r6plUOgrcp",
    "outputId": "3506f37b-d3e0-4070-bc24-c4721d9ee472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "112/112 [==============================] - 1s 2ms/step - loss: 0.3833 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.5410e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 0s 991us/step - loss: 4.9367e-04 - accuracy: 1.0000 - val_loss: 5.6121e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 6.3466e-06 - accuracy: 1.0000 - val_loss: 8.4825e-09 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 5.0894e-08 - accuracy: 1.0000 - val_loss: 1.5137e-09 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 7.5345e-09 - accuracy: 1.0000 - val_loss: 6.9629e-10 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 4.6950e-09 - accuracy: 1.0000 - val_loss: 4.3819e-10 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 0s 995us/step - loss: 5.7401e-09 - accuracy: 1.0000 - val_loss: 3.1573e-10 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 4.2435e-09 - accuracy: 1.0000 - val_loss: 2.4528e-10 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - 0s 2ms/step - loss: 6.4325e-09 - accuracy: 1.0000 - val_loss: 1.9979e-10 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "112/112 [==============================] - 0s 998us/step - loss: 3.8610e-09 - accuracy: 1.0000 - val_loss: 1.6812e-10 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 7.1628e-09 - accuracy: 1.0000 - val_loss: 1.4488e-10 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 6.5912e-09 - accuracy: 1.0000 - val_loss: 1.2712e-10 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 5.0938e-09 - accuracy: 1.0000 - val_loss: 1.1313e-10 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 6.1893e-09 - accuracy: 1.0000 - val_loss: 1.0184e-10 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 8.6541e-09 - accuracy: 1.0000 - val_loss: 9.2540e-11 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 5.3790e-09 - accuracy: 1.0000 - val_loss: 8.6146e-11 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "112/112 [==============================] - 0s 988us/step - loss: 4.5355e-09 - accuracy: 1.0000 - val_loss: 7.9337e-11 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "112/112 [==============================] - 0s 957us/step - loss: 3.6819e-09 - accuracy: 1.0000 - val_loss: 7.3493e-11 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 2.5329e-09 - accuracy: 1.0000 - val_loss: 6.8430e-11 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x239c4c3bdc8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,train_label,\n",
    "          epochs=20,\n",
    "          batch_size=1,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4Xjn8mhkRRj",
    "outputId": "e6b576a6-5bb1-474f-e0c0-ee9303f302b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 987us/step - loss: 0.8819 - accuracy: 0.5025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8815244436264038, 0.5035461187362671]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5tYmfRdQm_dQ"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model=models.Sequential()\n",
    "  model.add(layers.Dense(24,activation='relu' ,input_shape=(34,)))\n",
    "  model.add(layers.Dense(16,activation='relu'))\n",
    "  model.add(layers.Dense(8,activation='relu'))\n",
    "  model.add(layers.Dense(1,activation='sigmoid'))\n",
    "  model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4XTIBE8Um3bE",
    "outputId": "5cc7a97e-6b87-400f-c0e0-12a90e29458c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 0s 679us/step - loss: 0.5909 - accuracy: 0.9353\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 677us/step - loss: 0.3878 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 651us/step - loss: 0.1444 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 661us/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 705us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 728us/step - loss: 2.8604e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 746us/step - loss: 2.9389e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 724us/step - loss: 3.3514e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 0s 695us/step - loss: 8.1848e-08 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 649us/step - loss: 3.2887e-08 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.1633e-08 - accuracy: 1.0000\n",
      "processing fold # 1\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 0s 702us/step - loss: 0.7335 - accuracy: 0.7673\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 703us/step - loss: 0.6160 - accuracy: 0.8679\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 649us/step - loss: 0.5082 - accuracy: 0.8074\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 684us/step - loss: 0.3604 - accuracy: 0.7873\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 693us/step - loss: 0.1990 - accuracy: 0.8395\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 659us/step - loss: 0.1285 - accuracy: 0.8805\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 669us/step - loss: 0.0874 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 654us/step - loss: 0.0652 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 0s 664us/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "processing fold # 2\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 0s 677us/step - loss: 0.6571 - accuracy: 0.9620\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 656us/step - loss: 0.4350 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 682us/step - loss: 0.2481 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 645us/step - loss: 0.1131 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 672us/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 684us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 674us/step - loss: 2.5516e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 661us/step - loss: 1.0049e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 0s 672us/step - loss: 3.3548e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 661us/step - loss: 1.9758e-08 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.2461e-09 - accuracy: 1.0000\n",
      "processing fold # 3\n",
      "Epoch 1/10\n",
      "106/106 [==============================] - 0s 669us/step - loss: 0.6593 - accuracy: 0.9076\n",
      "Epoch 2/10\n",
      "106/106 [==============================] - 0s 687us/step - loss: 0.4492 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "106/106 [==============================] - 0s 619us/step - loss: 0.2424 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "106/106 [==============================] - 0s 705us/step - loss: 0.0931 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "106/106 [==============================] - 0s 760us/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "106/106 [==============================] - 0s 634us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "106/106 [==============================] - 0s 653us/step - loss: 1.4232e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "106/106 [==============================] - 0s 630us/step - loss: 5.5152e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "106/106 [==============================] - 0s 669us/step - loss: 1.4614e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "106/106 [==============================] - 0s 669us/step - loss: 1.3369e-08 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x0000015AEADD3F78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 5.0785e-09 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "k=4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 10\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    " print('processing fold #', i)\n",
    "\n",
    " # Prepare the validation data: data from partition # k\n",
    " val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    " val_targets = train_label[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "\n",
    " # Prepare the training data: data from all other partitions\n",
    " partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],axis=0)\n",
    " partial_train_targets = np.concatenate([train_label[:i * num_val_samples],train_label[(i + 1) * num_val_samples:]],axis=0)\n",
    "\n",
    "\n",
    " # Build the Keras model (already compiled)\n",
    " model = build_model()\n",
    " # Train the model (in silent mode, verbose=0)\n",
    " model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=1)\n",
    " # Evaluate the model on the validation data\n",
    " all_scores.append(model.evaluate(val_data, val_targets, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgJjdWrCoLVB",
    "outputId": "18ff6e43-34b8-471e-e29d-5981ac41d2cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6.163278243320747e-08, 1.0],\n",
       " [0.0014059104723855853, 1.0],\n",
       " [5.246082235288441e-09, 1.0],\n",
       " [5.0784638716550035e-09, 1.0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BZziFflpEcF",
    "outputId": "7bf4d3e9-8d3b-4c5b-f833-c4d96d6500fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 748us/step - loss: 8.3322e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.332231793417577e-09, 1.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKAsusgZpadM",
    "outputId": "148d940e-d3ab-4b32-83ae-39169b63efc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step - loss: 8.3555e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.35547275812587e-09, 1.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(df.iloc[1:5, :-1],df.iloc[1:5,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " Ionosphere Data .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
